{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87313f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e12fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719a6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('large_files/r8-train-all-terms.txt', header=None, sep='\\t')\n",
    "test = pd.read_csv('large_files/r8-test-all-terms.txt', header=None, sep='\\t')\n",
    "train.columns = ['label', 'content']\n",
    "test.columns = ['label', 'content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5227854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer terminal systems cpml completes sale computer terminal systems inc said it has completed the sale of shares of its common stock and warrants to acquire an additional one mln shares to sedio n v of lugano switzerland for dlrs the company said the warrants are exercisable for five years at a purchase price of dlrs per share computer terminal said sedio also has the right to buy additional shares and increase its total holdings up to pct of the computer terminal s outstanding common stock under certain circumstances involving change of control at the company the company said if the conditions occur the warrants would be exercisable at a price equal to pct of its common stock s market price at the time not to exceed dlrs per share computer terminal also said it sold the technolgy rights to its dot matrix impact technology including any future improvements to woodco inc of houston tex for dlrs but it said it would continue to be the exclusive worldwide licensee of the technology for woodco the company said the moves were part of its reorganization plan and would help pay current operation costs and ensure product delivery computer terminal makes computer generated labels forms tags and ticket printers and terminals reuter \n",
      "\t acq\n"
     ]
    }
   ],
   "source": [
    "print(train.content[1])\n",
    "print(\"\\t\",train.label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66b85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveVectorizer:\n",
    "    def __init__(self):\n",
    "        print('loading word vectors...')\n",
    "        word2vec = {}\n",
    "        embedding = []\n",
    "        idx2word = []\n",
    "        with open('large_files/glove.6b/glove.6b.50d.txt', encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vec = np.asarray(values[1:], dtype='float32')\n",
    "                word2vec[word] = vec\n",
    "                embedding.append(vec)\n",
    "                idx2word.append(word)\n",
    "        print('Found %s word vectors.' % len(word2vec))\n",
    "        \n",
    "        self.word2vec = word2vec\n",
    "        self.embedding = np.array(embedding)\n",
    "        self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "        self.V, self.D = self.embedding.shape\n",
    "        \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, data):\n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in data:\n",
    "            tokens = sentence.lower().split()\n",
    "            vecs = []\n",
    "            for word in tokens:\n",
    "                if word in self.word2vec:\n",
    "                    vec = self.word2vec[word]\n",
    "                    vecs.append(vec)\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount +=1\n",
    "            n += 1\n",
    "        print(\"Number of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5ebee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Woord2VecVectorizer:\n",
    "    def __init__(self):\n",
    "        print('Loading in word vectors...')\n",
    "        self.word_vectors = KeyedVectors.load_word2vec_format('large_files/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "        print(\"Finished loading in word vectors\")\n",
    "        \n",
    "    def fit(self, data):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, data):\n",
    "        v = self.word_vectors.get_vector('king')\n",
    "        self.D = v.shape[0]\n",
    "        \n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in data:\n",
    "            tokens = sentence.split()\n",
    "            vecs = []\n",
    "            m = 0\n",
    "            for word in tokens:\n",
    "                try:\n",
    "                    vec = self.word_vectors.get_vector(word)\n",
    "                    vecs.append(vec)\n",
    "                    m += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Number of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9e9ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word vectors...\n",
      "Found 400000 word vectors.\n",
      "Number of samples with no words found: 0 / 5485\n",
      "Number of samples with no words found: 0 / 5485\n"
     ]
    }
   ],
   "source": [
    "vectorizer = GloveVectorizer()\n",
    "Xtrain = vectorizer.fit_transform(train.content)\n",
    "Ytrain = train.label\n",
    "\n",
    "Xtest = vectorizer.fit_transform(train.content)\n",
    "Ytest = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63f3934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9992707383773929\n",
      "test score: 0.9992707383773929\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b8acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['earn' 'acq' 'trade' 'ship' 'grain' 'crude' 'interest' 'money-fx']\n"
     ]
    }
   ],
   "source": [
    "print(Ytest.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "055fcee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42225829  0.07437593  0.26020068  0.23492537  0.29256091  0.08535112\n",
      " -0.35343158 -0.39948615  0.09618001  0.00716475  0.16270347  0.08050574\n",
      " -0.25246552 -0.2461143   0.31502548  0.28226331 -0.16852508  0.01078145\n",
      " -0.33009204 -0.39175874  0.45302069 -0.11710789 -0.06598587 -0.1905102\n",
      " -0.26123828 -1.29367924 -0.14937761 -0.11885012  0.0887498  -0.05608343\n",
      "  3.09159064  0.10806133 -0.07475229 -0.14376929  0.14825106 -0.25082457\n",
      " -0.003683    0.04742439  0.10568412 -0.13436335 -0.03710696  0.01067496\n",
      "  0.2158376   0.16028534 -0.23386878  0.07255986 -0.14271812  0.17860013\n",
      " -0.03726814  0.00975073]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5cae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
